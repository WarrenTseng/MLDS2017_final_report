{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics Inference for Different Learning Rate and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats as st\n",
    "import pandas as pd\n",
    "\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l_mu_train = dict()\n",
    "l_mu_test = dict()\n",
    "\n",
    "l_mu_train_ = np.load('./loss_means_train_diffOP_lr0.0001.npy')\n",
    "l_mu_test_ = np.load('./loss_means_test_diffOP_lr0.0001.npy')\n",
    "for op, mu in l_mu_train_[None][0].items():\n",
    "    l_mu_train[op+'_0.0001'] = mu\n",
    "for op, mu in l_mu_test_[None][0].items():\n",
    "    l_mu_test[op+'_0.0001'] = mu\n",
    "    \n",
    "l_mu_train_ = np.load('./loss_means_train_diffOP_lr0.001.npy')\n",
    "l_mu_test_ = np.load('./loss_means_test_diffOP_lr0.001.npy')\n",
    "for op, mu in l_mu_train_[None][0].items():\n",
    "    l_mu_train[op+'_0.001'] = mu\n",
    "for op, mu in l_mu_test_[None][0].items():\n",
    "    l_mu_test[op+'_0.001'] = mu\n",
    "    \n",
    "l_mu_train_ = np.load('./loss_means_train_diffOP_lr0.01.npy')\n",
    "l_mu_test_ = np.load('./loss_means_test_diffOP_lr0.01.npy')\n",
    "for op, mu in l_mu_train_[None][0].items():\n",
    "    l_mu_train[op+'_0.01'] = mu\n",
    "for op, mu in l_mu_test_[None][0].items():\n",
    "    l_mu_test[op+'_0.01'] = mu\n",
    "\n",
    "l_mu_train_ = np.load('./loss_means_train_diffOP_lr0.1.npy')\n",
    "l_mu_test_ = np.load('./loss_means_test_diffOP_lr0.1.npy')\n",
    "for op, mu in l_mu_train_[None][0].items():\n",
    "    l_mu_train[op+'_0.1'] = mu\n",
    "for op, mu in l_mu_test_[None][0].items():\n",
    "    l_mu_test[op+'_0.1'] = mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loss - two-way ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_means</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.401298</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.386691</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.430036</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.752134</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.758048</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.084794</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.427183</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.439001</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.489705</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.159992</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.472989</td>\n",
       "      <td>GD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.507751</td>\n",
       "      <td>GD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.495200</td>\n",
       "      <td>GD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.470177</td>\n",
       "      <td>GD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.433655</td>\n",
       "      <td>GD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.448137</td>\n",
       "      <td>GD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.487232</td>\n",
       "      <td>GD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.471838</td>\n",
       "      <td>GD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.491459</td>\n",
       "      <td>GD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.446436</td>\n",
       "      <td>GD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.249800</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.203675</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.181839</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.154610</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.171922</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.203691</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.160584</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.131940</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.191375</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.181196</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.345959</td>\n",
       "      <td>AdaGD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.365331</td>\n",
       "      <td>AdaGD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.358368</td>\n",
       "      <td>AdaGD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.354007</td>\n",
       "      <td>AdaGD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.379417</td>\n",
       "      <td>AdaGD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.352740</td>\n",
       "      <td>AdaGD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.357888</td>\n",
       "      <td>AdaGD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.394055</td>\n",
       "      <td>AdaGD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.355981</td>\n",
       "      <td>AdaGD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.347202</td>\n",
       "      <td>AdaGD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.063838</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.042568</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.051846</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.044120</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.051786</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.060814</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.058399</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.050345</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.052663</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.050804</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.088540</td>\n",
       "      <td>RMS</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.079440</td>\n",
       "      <td>RMS</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.082969</td>\n",
       "      <td>RMS</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.086961</td>\n",
       "      <td>RMS</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.084318</td>\n",
       "      <td>RMS</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.076359</td>\n",
       "      <td>RMS</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.084831</td>\n",
       "      <td>RMS</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.079554</td>\n",
       "      <td>RMS</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.101174</td>\n",
       "      <td>RMS</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.080002</td>\n",
       "      <td>RMS</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     loss_means optimizer learning_rate\n",
       "0      2.401298      Adam           0.1\n",
       "1      1.386691      Adam           0.1\n",
       "2      2.430036      Adam           0.1\n",
       "3      1.752134      Adam           0.1\n",
       "4      1.758048      Adam           0.1\n",
       "5      2.084794      Adam           0.1\n",
       "6      2.427183      Adam           0.1\n",
       "7      2.439001      Adam           0.1\n",
       "8      1.489705      Adam           0.1\n",
       "9      2.159992      Adam           0.1\n",
       "10     0.472989        GD         0.001\n",
       "11     0.507751        GD         0.001\n",
       "12     0.495200        GD         0.001\n",
       "13     0.470177        GD         0.001\n",
       "14     0.433655        GD         0.001\n",
       "15     0.448137        GD         0.001\n",
       "16     0.487232        GD         0.001\n",
       "17     0.471838        GD         0.001\n",
       "18     0.491459        GD         0.001\n",
       "19     0.446436        GD         0.001\n",
       "20     0.249800      Adam          0.01\n",
       "21     0.203675      Adam          0.01\n",
       "22     0.181839      Adam          0.01\n",
       "23     0.154610      Adam          0.01\n",
       "24     0.171922      Adam          0.01\n",
       "25     0.203691      Adam          0.01\n",
       "26     0.160584      Adam          0.01\n",
       "27     0.131940      Adam          0.01\n",
       "28     0.191375      Adam          0.01\n",
       "29     0.181196      Adam          0.01\n",
       "..          ...       ...           ...\n",
       "130    0.345959     AdaGD         0.001\n",
       "131    0.365331     AdaGD         0.001\n",
       "132    0.358368     AdaGD         0.001\n",
       "133    0.354007     AdaGD         0.001\n",
       "134    0.379417     AdaGD         0.001\n",
       "135    0.352740     AdaGD         0.001\n",
       "136    0.357888     AdaGD         0.001\n",
       "137    0.394055     AdaGD         0.001\n",
       "138    0.355981     AdaGD         0.001\n",
       "139    0.347202     AdaGD         0.001\n",
       "140    0.063838      Adam         0.001\n",
       "141    0.042568      Adam         0.001\n",
       "142    0.051846      Adam         0.001\n",
       "143    0.044120      Adam         0.001\n",
       "144    0.051786      Adam         0.001\n",
       "145    0.060814      Adam         0.001\n",
       "146    0.058399      Adam         0.001\n",
       "147    0.050345      Adam         0.001\n",
       "148    0.052663      Adam         0.001\n",
       "149    0.050804      Adam         0.001\n",
       "150    0.088540       RMS        0.0001\n",
       "151    0.079440       RMS        0.0001\n",
       "152    0.082969       RMS        0.0001\n",
       "153    0.086961       RMS        0.0001\n",
       "154    0.084318       RMS        0.0001\n",
       "155    0.076359       RMS        0.0001\n",
       "156    0.084831       RMS        0.0001\n",
       "157    0.079554       RMS        0.0001\n",
       "158    0.101174       RMS        0.0001\n",
       "159    0.080002       RMS        0.0001\n",
       "\n",
       "[160 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.core.frame.DataFrame()\n",
    "loss_means = list()\n",
    "optimizer = list()\n",
    "learning_rate = list()\n",
    "for op_lr, mus in l_mu_train.items():\n",
    "    # split optimizer and learning rate\n",
    "    op, lr = op_lr.split(sep='_')\n",
    "    # create panda frame\n",
    "    for mu in mus:\n",
    "        loss_means.append(mu)\n",
    "        optimizer.append(op)\n",
    "        learning_rate.append(lr)\n",
    "data_train['loss_means'] = loss_means\n",
    "data_train['optimizer'] = optimizer\n",
    "data_train['learning_rate'] = learning_rate\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  sum_sq     df           F        PR(>F)\n",
      "C(optimizer)                    0.126349    3.0    1.754446  1.585867e-01\n",
      "C(learning_rate)               26.455671    3.0  367.356391  3.021056e-67\n",
      "C(optimizer):C(learning_rate)  48.838101    9.0  226.050948  2.719803e-80\n",
      "Residual                        3.456785  144.0         NaN           NaN\n"
     ]
    }
   ],
   "source": [
    "formula = 'loss_means ~ C(optimizer) + C(learning_rate) + C(optimizer):C(learning_rate)'\n",
    "model = ols(formula, data_train).fit()\n",
    "aov_table = statsmodels.stats.anova.anova_lm(model, typ=2)\n",
    "print(aov_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing loss two-way ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_means</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.445693</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.436156</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.482439</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.758835</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.761509</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.118381</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.480024</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.486228</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.496090</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.192349</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.488114</td>\n",
       "      <td>GD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.537679</td>\n",
       "      <td>GD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.518439</td>\n",
       "      <td>GD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.516778</td>\n",
       "      <td>GD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.472816</td>\n",
       "      <td>GD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.482766</td>\n",
       "      <td>GD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.517327</td>\n",
       "      <td>GD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.509864</td>\n",
       "      <td>GD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.529979</td>\n",
       "      <td>GD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.485747</td>\n",
       "      <td>GD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.300134</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.239471</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.238963</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.198198</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.214526</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.250131</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.211489</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.168498</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.241004</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.227036</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.350778</td>\n",
       "      <td>AdaGD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.381759</td>\n",
       "      <td>AdaGD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.366002</td>\n",
       "      <td>AdaGD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.386024</td>\n",
       "      <td>AdaGD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.391920</td>\n",
       "      <td>AdaGD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.381333</td>\n",
       "      <td>AdaGD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.363759</td>\n",
       "      <td>AdaGD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.409504</td>\n",
       "      <td>AdaGD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.373417</td>\n",
       "      <td>AdaGD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.356946</td>\n",
       "      <td>AdaGD</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.091912</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.079848</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.078715</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.075364</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.094163</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.102875</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.087339</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.081674</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.080381</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.090902</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.167222</td>\n",
       "      <td>RMS</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.153505</td>\n",
       "      <td>RMS</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.153678</td>\n",
       "      <td>RMS</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.168264</td>\n",
       "      <td>RMS</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.166079</td>\n",
       "      <td>RMS</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.147602</td>\n",
       "      <td>RMS</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.153217</td>\n",
       "      <td>RMS</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.154249</td>\n",
       "      <td>RMS</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.179959</td>\n",
       "      <td>RMS</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.156127</td>\n",
       "      <td>RMS</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     loss_means optimizer learning_rate\n",
       "0      2.445693      Adam           0.1\n",
       "1      1.436156      Adam           0.1\n",
       "2      2.482439      Adam           0.1\n",
       "3      1.758835      Adam           0.1\n",
       "4      1.761509      Adam           0.1\n",
       "5      2.118381      Adam           0.1\n",
       "6      2.480024      Adam           0.1\n",
       "7      2.486228      Adam           0.1\n",
       "8      1.496090      Adam           0.1\n",
       "9      2.192349      Adam           0.1\n",
       "10     0.488114        GD         0.001\n",
       "11     0.537679        GD         0.001\n",
       "12     0.518439        GD         0.001\n",
       "13     0.516778        GD         0.001\n",
       "14     0.472816        GD         0.001\n",
       "15     0.482766        GD         0.001\n",
       "16     0.517327        GD         0.001\n",
       "17     0.509864        GD         0.001\n",
       "18     0.529979        GD         0.001\n",
       "19     0.485747        GD         0.001\n",
       "20     0.300134      Adam          0.01\n",
       "21     0.239471      Adam          0.01\n",
       "22     0.238963      Adam          0.01\n",
       "23     0.198198      Adam          0.01\n",
       "24     0.214526      Adam          0.01\n",
       "25     0.250131      Adam          0.01\n",
       "26     0.211489      Adam          0.01\n",
       "27     0.168498      Adam          0.01\n",
       "28     0.241004      Adam          0.01\n",
       "29     0.227036      Adam          0.01\n",
       "..          ...       ...           ...\n",
       "130    0.350778     AdaGD         0.001\n",
       "131    0.381759     AdaGD         0.001\n",
       "132    0.366002     AdaGD         0.001\n",
       "133    0.386024     AdaGD         0.001\n",
       "134    0.391920     AdaGD         0.001\n",
       "135    0.381333     AdaGD         0.001\n",
       "136    0.363759     AdaGD         0.001\n",
       "137    0.409504     AdaGD         0.001\n",
       "138    0.373417     AdaGD         0.001\n",
       "139    0.356946     AdaGD         0.001\n",
       "140    0.091912      Adam         0.001\n",
       "141    0.079848      Adam         0.001\n",
       "142    0.078715      Adam         0.001\n",
       "143    0.075364      Adam         0.001\n",
       "144    0.094163      Adam         0.001\n",
       "145    0.102875      Adam         0.001\n",
       "146    0.087339      Adam         0.001\n",
       "147    0.081674      Adam         0.001\n",
       "148    0.080381      Adam         0.001\n",
       "149    0.090902      Adam         0.001\n",
       "150    0.167222       RMS        0.0001\n",
       "151    0.153505       RMS        0.0001\n",
       "152    0.153678       RMS        0.0001\n",
       "153    0.168264       RMS        0.0001\n",
       "154    0.166079       RMS        0.0001\n",
       "155    0.147602       RMS        0.0001\n",
       "156    0.153217       RMS        0.0001\n",
       "157    0.154249       RMS        0.0001\n",
       "158    0.179959       RMS        0.0001\n",
       "159    0.156127       RMS        0.0001\n",
       "\n",
       "[160 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.core.frame.DataFrame()\n",
    "loss_means = list()\n",
    "optimizer = list()\n",
    "learning_rate = list()\n",
    "for op_lr, mus in l_mu_test.items():\n",
    "    # split optimizer and learning rate\n",
    "    op, lr = op_lr.split(sep='_')\n",
    "    # create panda frame\n",
    "    for mu in mus:\n",
    "        loss_means.append(mu)\n",
    "        optimizer.append(op)\n",
    "        learning_rate.append(lr)\n",
    "data_test['loss_means'] = loss_means\n",
    "data_test['optimizer'] = optimizer\n",
    "data_test['learning_rate'] = learning_rate\n",
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  sum_sq     df           F        PR(>F)\n",
      "C(optimizer)                    0.148037    3.0    2.110551  1.014824e-01\n",
      "C(learning_rate)               27.907000    3.0  397.868252  1.842872e-69\n",
      "C(optimizer):C(learning_rate)  47.329043    9.0  224.922349  3.803462e-80\n",
      "Residual                        3.366783  144.0         NaN           NaN\n"
     ]
    }
   ],
   "source": [
    "formula = 'loss_means ~ C(optimizer) + C(learning_rate) + C(optimizer):C(learning_rate)'\n",
    "model = ols(formula, data_test).fit()\n",
    "aov_table = statsmodels.stats.anova.anova_lm(model, typ=2)\n",
    "print(aov_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training loss t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sort them by means\n",
    "mean = dict()\n",
    "StD = dict()\n",
    "for op, mu in l_mu_train.items():\n",
    "    mean[op] = np.mean(mu)\n",
    "    StD[op] = np.std(mu)\n",
    "mus_sort = sorted(mean.values())\n",
    "ops_sort = sorted(mean, key=mean.__getitem__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       OP        mean     StD    \n",
      "   RMS_0.001    0.0105   0.0011\n",
      "    RMS_0.01    0.0327   0.0044\n",
      "  Adam_0.001    0.0527   0.0064\n",
      "  RMS_0.0001    0.0844   0.0066\n",
      "  AdaGD_0.01    0.0985   0.0123\n",
      " Adam_0.0001    0.1318   0.0076\n",
      "   Adam_0.01    0.1831   0.0307\n",
      "     GD_0.01    0.1885   0.0176\n",
      "      GD_0.1    0.2305   0.0316\n",
      "   AdaGD_0.1    0.2585   0.0557\n",
      " AdaGD_0.001    0.3611   0.0142\n",
      "    GD_0.001    0.4725   0.0226\n",
      "   GD_0.0001    1.3101   0.0910\n",
      "AdaGD_0.0001    1.3889   0.0682\n",
      "     RMS_0.1    2.0218   0.4200\n",
      "    Adam_0.1    2.0329   0.3873\n"
     ]
    }
   ],
   "source": [
    "print('       OP        mean     StD    ')\n",
    "for i in range(len(ops_sort)):\n",
    "    print('%12s    %2.4f   %2.4f' % (ops_sort[i], mus_sort[i], StD[ops_sort[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t value: 0.0582724125951 , P value: 0.954177864073\n",
      "Adam_0.1 = RMS_0.1\n",
      "\n",
      "t value: 4.46209011482 , P value: 0.00138502374569\n",
      "RMS_0.1 > AdaGD_0.0001\n",
      "\n",
      "t value: 2.07924414049 , P value: 0.0533447538453\n",
      "AdaGD_0.0001 = GD_0.0001\n",
      "\n",
      "t value: 26.8006990322 , P value: 1.00364533048e-10\n",
      "GD_0.0001 > GD_0.001\n",
      "\n",
      "t value: 12.4990267992 , P value: 2.18532219592e-09\n",
      "GD_0.001 > AdaGD_0.001\n",
      "\n",
      "t value: 5.35341321414 , P value: 0.000304092406886\n",
      "AdaGD_0.001 > AdaGD_0.1\n",
      "\n",
      "t value: 1.31057461866 , P value: 0.210746363908\n",
      "AdaGD_0.1 = GD_0.1\n",
      "\n",
      "t value: 3.48594652781 , P value: 0.00360841962016\n",
      "GD_0.1 > GD_0.01\n",
      "\n",
      "t value: 0.462940786539 , P value: 0.650366962584\n",
      "GD_0.01 = Adam_0.01\n",
      "\n",
      "t value: 4.8608698292 , P value: 0.000640709517257\n",
      "Adam_0.01 > Adam_0.0001\n",
      "\n",
      "t value: 6.87617315534 , P value: 5.27630714559e-06\n",
      "Adam_0.0001 > AdaGD_0.01\n",
      "\n",
      "t value: 3.02013468509 , P value: 0.00930966511433\n",
      "AdaGD_0.01 > RMS_0.0001\n",
      "\n",
      "t value: 10.3215301213 , P value: 5.54555844864e-09\n",
      "RMS_0.0001 > Adam_0.001\n",
      "\n",
      "t value: 7.72309876252 , P value: 8.66765469755e-07\n",
      "Adam_0.001 > RMS_0.01\n",
      "\n",
      "t value: 14.5720089214 , P value: 4.0464389843e-08\n",
      "RMS_0.01 > RMS_0.001\n",
      "\n",
      "Loss:: Adam_0.1 = RMS_0.1 > AdaGD_0.0001 = GD_0.0001 > GD_0.001 > AdaGD_0.001 > AdaGD_0.1 = GD_0.1 > GD_0.01 = Adam_0.01 > Adam_0.0001 > AdaGD_0.01 > RMS_0.0001 > Adam_0.001 > RMS_0.01 > RMS_0.001\n"
     ]
    }
   ],
   "source": [
    "# t-test for each means\n",
    "compare_flag = list() \n",
    "alpha = 0.05\n",
    "for i in range(len(l_mu_train)-1):\n",
    "    t_val, p_val = st.ttest_ind(l_mu_train[ops_sort[len(l_mu_train)-1-i]],\n",
    "                                l_mu_train[ops_sort[len(l_mu_train)-2-i]],\n",
    "                                equal_var=False)\n",
    "    print('t value:', t_val, ', P value:', p_val)\n",
    "    if p_val <= alpha:\n",
    "        print(ops_sort[len(l_mu_train)-1-i] + ' > ' + ops_sort[len(l_mu_train)-2-i])\n",
    "        compare_flag.append('>')\n",
    "    else:\n",
    "        print(ops_sort[len(l_mu_train)-1-i] + ' = ' + ops_sort[len(l_mu_train)-2-i])\n",
    "        compare_flag.append('=')\n",
    "    print('')\n",
    "# Result\n",
    "print('Loss::',\n",
    "      ops_sort[15], compare_flag[0], \n",
    "      ops_sort[14], compare_flag[1], \n",
    "      ops_sort[13], compare_flag[2],\n",
    "      ops_sort[12], compare_flag[3],\n",
    "      ops_sort[11], compare_flag[4],\n",
    "      ops_sort[10], compare_flag[5],\n",
    "      ops_sort[9], compare_flag[6],\n",
    "      ops_sort[8], compare_flag[7],\n",
    "      ops_sort[7], compare_flag[8],\n",
    "      ops_sort[6], compare_flag[9],\n",
    "      ops_sort[5], compare_flag[10],\n",
    "      ops_sort[4], compare_flag[11],\n",
    "      ops_sort[3], compare_flag[12],\n",
    "      ops_sort[2], compare_flag[13],\n",
    "      ops_sort[1], compare_flag[14],\n",
    "      ops_sort[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing loss t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sort them by means\n",
    "mean = dict()\n",
    "StD = dict()\n",
    "for op, mu in l_mu_test.items():\n",
    "    mean[op] = np.mean(mu)\n",
    "    StD[op] = np.std(mu)\n",
    "mus_sort = sorted(mean.values())\n",
    "ops_sort = sorted(mean, key=mean.__getitem__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       OP        mean     StD    \n",
      "   RMS_0.001    0.0803   0.0049\n",
      "  Adam_0.001    0.0863   0.0082\n",
      "    RMS_0.01    0.1472   0.0073\n",
      " Adam_0.0001    0.1475   0.0080\n",
      "  RMS_0.0001    0.1600   0.0094\n",
      "  AdaGD_0.01    0.1697   0.0145\n",
      "   Adam_0.01    0.2289   0.0331\n",
      "     GD_0.01    0.2802   0.0198\n",
      "      GD_0.1    0.3354   0.0326\n",
      "   AdaGD_0.1    0.3550   0.0566\n",
      " AdaGD_0.001    0.3761   0.0167\n",
      "    GD_0.001    0.5060   0.0209\n",
      "   GD_0.0001    1.2972   0.0962\n",
      "AdaGD_0.0001    1.3682   0.0745\n",
      "    Adam_0.1    2.0658   0.3991\n",
      "     RMS_0.1    2.2015   0.3945\n"
     ]
    }
   ],
   "source": [
    "print('       OP        mean     StD    ')\n",
    "for i in range(len(ops_sort)):\n",
    "    print('%12s    %2.4f   %2.4f' % (ops_sort[i], mus_sort[i], StD[ops_sort[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t value: 0.725815629465 , P value: 0.477285061454\n",
      "RMS_0.1 = Adam_0.1\n",
      "\n",
      "t value: 5.15449551861 , P value: 0.000483864076259\n",
      "Adam_0.1 > AdaGD_0.0001\n",
      "\n",
      "t value: 1.74857171449 , P value: 0.0984561513854\n",
      "AdaGD_0.0001 = GD_0.0001\n",
      "\n",
      "t value: 24.1162576009 , P value: 4.36859069995e-10\n",
      "GD_0.0001 > GD_0.001\n",
      "\n",
      "t value: 14.5561008015 , P value: 4.2907817206e-11\n",
      "GD_0.001 > AdaGD_0.001\n",
      "\n",
      "t value: 1.0724688581 , P value: 0.307413628981\n",
      "AdaGD_0.001 = AdaGD_0.1\n",
      "\n",
      "t value: 0.903041842334 , P value: 0.381393395205\n",
      "AdaGD_0.1 = GD_0.1\n",
      "\n",
      "t value: 4.34113935996 , P value: 0.00059332417895\n",
      "GD_0.1 > GD_0.01\n",
      "\n",
      "t value: 3.9810882901 , P value: 0.00124819011489\n",
      "GD_0.01 > Adam_0.01\n",
      "\n",
      "t value: 4.91365730766 , P value: 0.000331681584383\n",
      "Adam_0.01 > AdaGD_0.01\n",
      "\n",
      "t value: 1.68647340225 , P value: 0.111782917077\n",
      "AdaGD_0.01 = RMS_0.0001\n",
      "\n",
      "t value: 3.03787234383 , P value: 0.00723792170871\n",
      "RMS_0.0001 > Adam_0.0001\n",
      "\n",
      "t value: 0.0718677535747 , P value: 0.943504917676\n",
      "Adam_0.0001 = RMS_0.01\n",
      "\n",
      "t value: 16.6485714812 , P value: 2.67849779707e-12\n",
      "RMS_0.01 > Adam_0.001\n",
      "\n",
      "t value: 1.89533759137 , P value: 0.0778313211479\n",
      "Adam_0.001 = RMS_0.001\n",
      "\n",
      "Loss:: RMS_0.1 = Adam_0.1 > AdaGD_0.0001 = GD_0.0001 > GD_0.001 > AdaGD_0.001 = AdaGD_0.1 = GD_0.1 > GD_0.01 > Adam_0.01 > AdaGD_0.01 = RMS_0.0001 > Adam_0.0001 = RMS_0.01 > Adam_0.001 = RMS_0.001\n"
     ]
    }
   ],
   "source": [
    "# t-test for each means\n",
    "compare_flag = list() \n",
    "alpha = 0.05\n",
    "for i in range(len(l_mu_test)-1):\n",
    "    t_val, p_val = st.ttest_ind(l_mu_test[ops_sort[len(l_mu_test)-1-i]],\n",
    "                                l_mu_test[ops_sort[len(l_mu_test)-2-i]],\n",
    "                                equal_var=False)\n",
    "    print('t value:', t_val, ', P value:', p_val)\n",
    "    if p_val <= alpha:\n",
    "        print(ops_sort[len(l_mu_test)-1-i] + ' > ' + ops_sort[len(l_mu_test)-2-i])\n",
    "        compare_flag.append('>')\n",
    "    else:\n",
    "        print(ops_sort[len(l_mu_test)-1-i] + ' = ' + ops_sort[len(l_mu_test)-2-i])\n",
    "        compare_flag.append('=')\n",
    "    print('')\n",
    "# Result\n",
    "print('Loss::',\n",
    "      ops_sort[15], compare_flag[0], \n",
    "      ops_sort[14], compare_flag[1], \n",
    "      ops_sort[13], compare_flag[2],\n",
    "      ops_sort[12], compare_flag[3],\n",
    "      ops_sort[11], compare_flag[4],\n",
    "      ops_sort[10], compare_flag[5],\n",
    "      ops_sort[9], compare_flag[6],\n",
    "      ops_sort[8], compare_flag[7],\n",
    "      ops_sort[7], compare_flag[8],\n",
    "      ops_sort[6], compare_flag[9],\n",
    "      ops_sort[5], compare_flag[10],\n",
    "      ops_sort[4], compare_flag[11],\n",
    "      ops_sort[3], compare_flag[12],\n",
    "      ops_sort[2], compare_flag[13],\n",
    "      ops_sort[1], compare_flag[14],\n",
    "      ops_sort[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
